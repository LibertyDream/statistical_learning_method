{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯法是常用分类方法。先学习联合概率分布，然后用贝叶斯定理求最大后验概率输出 $y$。实际上是学习数据生成机制，是生成模型。\n",
    "\n",
    "- [4.1 朴素贝叶斯法的学习与分类](#4.1-朴素贝叶斯法的学习与分类)\n",
    "  - [4.1.1 基本方法](#4.1.1-基本方法)\n",
    "  - [4.1.2 后验概率最大化的含义](#4.1.2-后验概率最大化的含义)\n",
    "- [4.2 朴素贝叶斯法的参数估计](#4.2-朴素贝叶斯法的参数估计)\n",
    "  - [4.2.1 极大似然估计](#4.2.1-极大似然估计)\n",
    "  - [4.2.2 学习与分类算法](#4.2.2-学习与分类算法)\n",
    "  - [4.2.3 贝叶斯估计](#4.2.3-贝叶斯估计)\n",
    "- [算法实现](#算法实现)\n",
    "- [习题](#习题)\n",
    "\n",
    "# 4.1 朴素贝叶斯法的学习与分类\n",
    "\n",
    "## 4.1.1 基本方法\n",
    "\n",
    "输入的 $x \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}$ 是 n 维向量，输出为 $y \\in \\mathcal{Y} = \\left\\{c_{1}, c_{2}, \\cdots, c_{K}\\right\\}$，是类标记(class label)。朴素贝叶斯法通过训练集学习联合概率分布 $P(X|Y)$ 。首先，学习先验概率分布 $P\\left(Y=c_{k}\\right)$，$ k=1,2, \\cdots, K$，再学习条件概率分布 $P\\left(X=x | Y=c_{k}\\right)=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right)$，这样就得到了 $P(X|Y)$。\n",
    "\n",
    "为方便计算，朴素贝叶斯法假定分类的特征在类别确定的情况下都是条件独立的，即：\n",
    "$$\n",
    "\\begin{aligned} P\\left(X=x | Y=c_{k}\\right) &=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}\n",
    "$$\n",
    "进行分类时，对给定的 $x$，通过学习到的模型计算后验概率：\n",
    "$$\n",
    "P\\left(Y=c_{k} | X=x\\right)=\\frac{P\\left(X=x | Y=c_{k}\\right) P\\left(Y=c_{k}\\right)}{\\sum_{k} P\\left(X=x | Y=c_{k}\\right) P\\left(Y=c_{k}\\right)}\n",
    "$$\n",
    "在给定条件独立性假设的情况下：\n",
    "$$\n",
    "P\\left(Y=c_{k} | X=x\\right)=\\frac{P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)} {\\sum_{k} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)}\n",
    "$$\n",
    "于是朴素贝叶斯分类器可以表示为：\n",
    "$$\n",
    "{y=f(x)=\\arg \\max _{c_{k}} \\frac{P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)}{\\sum_{k} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)}}\n",
    "$$\n",
    "注意到对任意 $c_{k}$ 上式分母是固定值，所以\n",
    "$$\n",
    "y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)\n",
    "$$\n",
    "\n",
    "## 4.1.2 后验概率最大化的含义\n",
    "\n",
    "朴素贝叶斯法将 $x$ 分配给后验概率最大的类中，等价于期望风险最小化。\n",
    "\n",
    "假定采用 0-1 损失函数，此时期望风险为：\n",
    "$$\n",
    "R_{\\exp }(f)=E[L(Y, f(X))]=E_{X} \\sum_{k=1}^{K}\\left[L\\left(c_{k}, f(X)\\right)\\right] P\\left(c_{k} | X\\right)\n",
    "$$\n",
    "为了使期望风险最小，只需要对每个 $X=x$ 极小化，即:\n",
    "$$\n",
    "\\begin{aligned} f(x) &=\\arg \\min _{y \\in \\mathcal{Y}} \\sum_{k=1}^{K} L\\left(c_{k}, y\\right) P\\left(c_{k} | X=x\\right) \\\\ &=\\arg \\min _{y \\in \\mathcal{Y}} \\sum_{k=1}^{K} P\\left(y \\neq c_{k} | X=x\\right) \\\\ &=\\arg \\min _{y \\in \\mathcal{Y}}\\left(1-P\\left(y=c_{k} | X=x\\right)\\right) \\\\ &=\\arg \\max _{y \\in \\mathcal{Y}} P\\left(y=c_{k} | X=x\\right) \\end{aligned}\n",
    "$$\n",
    "这样就由期望风险最小得到了后验概率最大准则，即朴素贝叶斯法采用的形式。\n",
    "\n",
    "# 4.2 朴素贝叶斯法的参数估计\n",
    "\n",
    "## 4.2.1 极大似然估计\n",
    "\n",
    "因为要先学习两个先验概率 $P(c_{k})$ 和 $P(x^{(j)}|c_{k})$，可以使用极大似然估计：\n",
    "$$\n",
    "P\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}\n",
    "$$\n",
    "$I$ 是指示函数。进一步假设第 $j$  个特征 $x^{(j)}$ 的取值集合为 $\\left\\{a_{j 1}, a_{j 2}, \\cdots, a_{j S_{j}}\\right\\}$ ，则：\n",
    "$$\n",
    "P\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}\n",
    "$$\n",
    "\n",
    "## 4.2.2 学习与分类算法\n",
    "\n",
    "1. 求先验概率和条件概率\n",
    "\n",
    "$$\n",
    "P\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}, \\quad k=1,2, \\cdots, K\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}{P\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}} \\\\ {j=1,2, \\cdots, n ; \\quad l=1,2, \\cdots, S_{j} ; \\quad k=1,2, \\cdots, K}\\end{array}\n",
    "$$\n",
    "\n",
    "2. 给定实例 $x=\\left(x^{(1)}, x^{(2)}, \\cdots, x^{(n)}\\right)^{\\mathrm{T}}$，计算：\n",
    "\n",
    "$$\n",
    "P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right), \\quad k=1,2, \\cdots, K\n",
    "$$\n",
    "\n",
    "3. 确定 $x$ 的类别：\n",
    "\n",
    "$$\n",
    "y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)\n",
    "$$\n",
    "\n",
    "## 4.2.3 贝叶斯估计\n",
    "\n",
    "极大似然估计可能会使某些估计的概率为 0，从而导致后验概率计算时出现偏颇。解决这一问题可以使用贝叶斯估计\n",
    "\n",
    "后验概率的贝叶斯估计：\n",
    "$$\n",
    "P_{\\lambda}\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+S_{j} \\lambda}\n",
    "$$\n",
    "先验概率的贝叶斯估计：\n",
    "$$\n",
    "P_{\\lambda}\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\lambda}{N+K \\lambda}\n",
    "$$\n",
    "式中 $\\lambda \\geqslant 0$，等价于每个变量取值的频数之上再加一个 $\\lambda > 0$。当 $\\lambda = 0$ 时是极大似然估计，常取 $\\lambda = 1$，称为拉普拉斯平滑(Laplacian smoothing)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法实现\n",
    "\n",
    "**加载需要的库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**硬件与版本信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.7.0\n",
      "\n",
      "ipywidgets 7.5.1\n",
      "matplotlib 3.1.0\n",
      "numpy 1.16.4\n",
      "pandas 0.25.0\n",
      "sklearn 0.21.2\n",
      "\n",
      "compiler   : MSC v.1915 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p ipywidgets,matplotlib,numpy,pandas,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**准备数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris();\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    dataset = df.loc[(df['label'] == 0) | (df['label'] == 1),:]\n",
    "    X = dataset.loc[:,'sepal length':'petal width']\n",
    "    y = dataset['label']\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.5, 2.4, 3.7, 1. ]), 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**高斯模型**\n",
    "\n",
    "假设特征分布为高斯分布，则其概率密度函数为：\n",
    "\n",
    "$$\n",
    "P(X | Y=c)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{c}^{2}}} e^{\\frac{-\\left(x-\\mu_{c}\\right)^{2}}{2 \\sigma_{c}^{2}}}\n",
    "$$\n",
    "\n",
    "为防止分类偏颇，出现除以 0 的情形，加上 $\\lambda > 0$\n",
    "\n",
    "$$\n",
    "P(X | Y=c)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{c}^{2}+ \\lambda}} e^{\\frac{-\\left(x-\\mu_{c}\\right)^{2}}{2 \\sigma_{c}^{2}+\\lambda}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_Gaussian():\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"按类别算好均值、方差\"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = []\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[np.where(y == c)]\n",
    "            self.parameters.append([])\n",
    "            \n",
    "            for col in X_c.T:\n",
    "                parameters = {'mean':col.mean(),'var':col.var()}\n",
    "                self.parameters[i].append(parameters)\n",
    "    \n",
    "    def __cal_possibility(self, mean, var, x):\n",
    "        \"\"\"给定 x 的概率\"\"\"\n",
    "        lam = 1e-4\n",
    "        coeff = 1.0 / math.sqrt(2 * math.pi * var + lam)\n",
    "        exp = math.exp(-(math.pow(x - mean,2)/(2 * var + lam)))\n",
    "        return coeff * exp\n",
    "    \n",
    "    def __cal_prior(self, c):\n",
    "        \"\"\"类别 c 的先验概率\"\"\"\n",
    "        freq = np.mean(self.y == c)\n",
    "        return freq\n",
    "    \n",
    "    def __classify(self, sample):\n",
    "        \"\"\"对 sample 进行分类，求最大后验概率\"\"\"\n",
    "        posteriors = []\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            posterior = self.__cal_prior(c)\n",
    "            \n",
    "            for x, params in zip(sample, self.parameters[i]):\n",
    "                possibility = self.__cal_possibility(params['mean'],params['var'],x)\n",
    "                posterior *= possibility\n",
    "            \n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self.__classify(x) for x in X]\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        correct = 0\n",
    "        for pred, act in zip(y_pred, y_test):\n",
    "            if pred == act:\n",
    "                correct += 1\n",
    "        return correct / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NB_Gaussian()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict([[4.4, 3.2, 1.3, 0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scikit-learn**\n",
    "\n",
    "scikit-learn 库中有伯努利模型（BernoulliNB），高斯模型（GaussianNB）和多项式模型（MultinomialNB）三种朴素贝叶斯方法的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(gnb.predict([[4.4, 3.2, 1.3, 0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伯努利模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(bnb.predict([[4.4, 3.2, 1.3, 0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(mnb.predict([[4.4, 3.2, 1.3, 0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 习题\n",
    "\n",
    "**4.1 用极大似然估计法推导朴素贝叶斯法中的先验概率估计公式(4.8)和条件概率估计公式(4.9)**\n",
    "\n",
    "① 求证：$P\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}$\n",
    "\n",
    "证明：\n",
    "\n",
    "极大似然假设样本是独立同分布的，对任意样本结果 $y$ 和标记类别 $c_k$，只有 $P(y = c_{k}) = p，P(y \\neq c_{k}) = 1-p$ 两种，所以\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=c_{k}) &= p^{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}(1-p)^{\\sum_{i=1}^{N} I\\left(y_{i} \\neq c_{k}\\right)} \\\\\n",
    "\\log P(Y=c_{k})&= \\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right) \\log p + \\sum_{i=1}^{N} I\\left(y_{i} \\neq c_{k}\\right)\\log(1-p) \\\\\n",
    "L(p)=\\frac{\\partial \\log P(Y=c_{k})}{\\partial p} &= \\frac {\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{p}-\\frac{\\sum_{i=1}^{N} I\\left(y_{i} \\neq c_{k}\\right)}{1-p}\n",
    "\\end{aligned}\n",
    "$$\n",
    "令 $L(p) = 0$，得\n",
    "$$\n",
    "p = \\frac {\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\sum_{i=1}^{N} I\\left(y_{i} \\neq c_{k}\\right)}=\\frac {\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}\n",
    "$$\n",
    "②求证：$P\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}$\n",
    "\n",
    "证明：\n",
    "\n",
    "道理同①，有\n",
    "$$\n",
    "P\\left(Y=c_{k}, x^{(j)}=a_{j l}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}, x_{i}^{(j)}=a_{j l}\\right)}{N}\n",
    "$$\n",
    "进而：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P\\left(x^{(j)}=a_{j l} | Y=c_{k}\\right)&=\\frac{P\\left(Y=c_{k}, x^{(j)}=a_{j l}\\right)}{P\\left(Y=c_{k}\\right)}\\\\\n",
    "&=\\frac{\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}, x_{i}^{(j)}=a_{j l}\\right)}{N}} {\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}{N}} \\\\\n",
    "&=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}, x_{i}^{(j)}=a_{j l}\\right)}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "**4.2 用贝叶斯估计法推出朴素贝叶斯法中的概率估计公式(4.10)及公式(4.11)**\n",
    "\n",
    "①求证：$P_{\\lambda}\\left(Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\lambda}{N+K \\lambda}$，其中 $\\lambda$ 是估计参数，$K$ 是随机变量 $Y$ 的取值种数\n",
    "\n",
    "证明：\n",
    "\n",
    "假设 $Y$ 的先验分布为均匀分布，即 $p = P(Y=c_{k}) = \\frac {1}{K}$，就有\n",
    "$$\n",
    "pK -1 = 0 \\tag{1}\n",
    "$$\n",
    "从习题 4.1 可知\n",
    "$$\n",
    "pN -\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right) = 0 \\tag{2}\n",
    "$$\n",
    "取任意 $\\lambda \\geqslant 0$，有\n",
    "$$\n",
    "\\lambda(1) + (2) = 0  \\\\\n",
    "\\lambda(pK -1) + pN -\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right) = 0\n",
    "$$\n",
    "解得\n",
    "$$\n",
    "p = P(Y=c_{k}) = \\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\lambda}{N+K \\lambda} \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "②求证：$P_{\\lambda}\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+S_{j} \\lambda}$，$S_{j}$ 是 $x^{(j)}$ 的可取值个数\n",
    "\n",
    "证明：\n",
    "\n",
    "依然假设先验分布为均匀分布，则 $P\\left(X^{(j)}=a_{j l} , Y=c_{k}\\right) = \\frac{1}{KS_{j}}$ ，由①可知：\n",
    "$$\n",
    "P_{\\lambda}\\left(X^{(j)}=a_{j l} , Y=c_{k}\\right) =\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda_{1}}{N+KS_{j} \\lambda_{1}} \\tag{4}\n",
    "$$\n",
    "而\n",
    "$$\n",
    "P_{\\lambda}\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{P_{\\lambda}\\left(X^{(j)}=a_{j l} , Y=c_{k}\\right)}{P_{\\lambda}\\left(Y=c_{k}\\right)}\n",
    "$$\n",
    "将式$(3),(4)$带入可得\n",
    "$$\n",
    "P_{\\lambda}\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda_{1}}{N+K S_{j}\\lambda_{1}}}{\\frac{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+\\lambda_{2}}{N+K \\lambda_{2}} }\n",
    "$$\n",
    "取 $\\lambda_{2} = S_{j} \\lambda_{1}$，则\n",
    "$$\n",
    "P_{\\lambda}\\left(X^{(j)}=a_{j l} | Y=c_{k}\\right)=\\frac{\\sum_{i=1}^{N} I\\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\\right)+\\lambda_{1}}{\\sum_{i=1}^{N} I\\left(y_{i}=c_{k}\\right)+S_{j} \\lambda_{1}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "作者：Daniel Meng\n",
    "\n",
    "GitHub：[LibertyDream](https://github.com/LibertyDream)\n",
    "\n",
    "博客：[明月轩](https://libertydream.github.io/)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
