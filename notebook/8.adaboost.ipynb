{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost\n",
    "\n",
    "微观上，提升法（boosting）就是在分类问题中，每次放大错误样本的权重，学习多个分类器，前一个分类器的结果是下一个分类器的输入，如此迭代，最后将这些线性分类器线性组合得到最终分类器。是一个从弱学习算法提升到强学习算法的过程\n",
    "\n",
    "宏观上，提升法的代表 Adaboost 算法是模型为加法模型，损失函数为指数函数，学习算法为前向分布算法的二分类学习方法。\n",
    "\n",
    "**Adaboost 算法描述**\n",
    "\n",
    "输入：训练数据集$T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$，其中 $x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}, y_{i} \\in \\mathcal{Y} = \\{-1,+1\\}$；弱学习算法\n",
    "\n",
    "输出：最终分类器 $G(x)$\n",
    "\n",
    "1. 初始化数据的权重分布\n",
    "\n",
    "$$\n",
    "D_{1}=\\left(w_{11}, \\cdots, w_{1 i}, \\cdots, w_{1 N}\\right), \\quad w_{1 i}=\\frac{1}{N}, \\quad i=1,2, \\cdots, N\n",
    "$$\n",
    "\n",
    "2. 对 $m = 1,2,\\ldots,M$\n",
    "\n",
    "   1. 在权重分布为 $G_m$ 的数据集上学习基本分类器 $G_{m}(x): \\mathcal{X} \\rightarrow\\{-1,+1\\}$\n",
    "   2. 计算 $G_m$ 上的分类误差率  $e_{m}=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)$\n",
    "   3. 计算 $G_m(x)$ 的系数 $\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}$ ，取自然对数\n",
    "   4. 更新权重分布\n",
    "\n",
    "   $$\n",
    "   \\begin{array}{c}{D_{m+1}=\\left(w_{m+1,1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N}\\right)} \\\\ {w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, N}\\end{array}\n",
    "   $$\n",
    "\n",
    "   $Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)$ 是规范化因子，使 $D_{m+1}$ 成为一个概率分布\n",
    "\n",
    "3. 构建基本分类器的线性组合 $f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)$，得到最终分类器\n",
    "\n",
    "$$\n",
    "G(x) =\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\\right) \n",
    "$$\n",
    "\n",
    "adaboost的两个特点：\n",
    "\n",
    "- 不改变所给数据而是改变数据权值分布，使训练数据对不同分类器起不同作用\n",
    "- 利用基本分类器的线性组合构建最终分类器\n",
    "\n",
    "**加法模型解释**\n",
    "\n",
    "当把adaboost视为前向分步算法的一个实现，模型为加法模型 $f(x)=\\sum_{m=1}^{M} \\beta_{m} b\\left(x ; \\gamma_{m}\\right)$，指数损失函数，每一步实际是在极小化损失函数\n",
    "$$\n",
    "\\left(\\beta_{m}, \\gamma_{m}\\right)=\\arg \\min _{\\beta, \\gamma} \\sum_{i=1}^{N} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+\\beta b\\left(x_{i} ; \\gamma\\right)\\right)\n",
    "$$\n",
    "求取参数 $\\beta_{m}, \\gamma_{m}$\n",
    "\n",
    "# 提升树\n",
    "\n",
    "提升树是以分类树或回归树为基本分类器的提升方法。前者是二叉分类树用指数损失函数，后者是二叉回归树用平方误差损失函数。分类问题算作是 adaboost 算法的特例，对于回归问题实际是在拟合残差。\n",
    "\n",
    "回归树可以表示为 $T(x ; \\Theta)=\\sum_{j=1}^{J} c_{j} I\\left(x \\in R_{j}\\right)$，$R_j$ 是输入空间 $\\mathcal{X}$ 划分出的若干不相交区域之一，$c_j$ 是其上输出常量，$\\Theta$ 是决策树参数，表示各划分和各区域上的常数，$J$ 是叶结点数\n",
    "\n",
    "**回归问题提升树算法**\n",
    "\n",
    "输入：训练数据集 $T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$ ，$x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}, y_{i} \\in \\mathcal{Y}  \\subseteq \\mathbf{R}^{n}$；\n",
    "\n",
    "输出：提升树 $f_M(x)$\n",
    "\n",
    "1. 初始化 $f_0(x) = 0$\n",
    "\n",
    "2. 对 $m = 1,2,\\ldots,M$\n",
    "\n",
    "   1. 在树上计算残差\n",
    "\n",
    "   $$\n",
    "   r_{m i}=y_{i}-f_{m-1}\\left(x_{i}\\right), \\quad i=1,2, \\cdots, N\n",
    "   $$\n",
    "\n",
    "   2. 拟合残差得到回归树 $T(x ; \\Theta_m)$\n",
    "   3. 更新 $f_{m}(x)=f_{m-1}(x)+T\\left(x ; \\Theta_{m}\\right)$\n",
    "\n",
    "3. 得到问题的提升回归树 $f_{M}(x)=\\sum_{m=1}^{M} T\\left(x ; \\Theta_{m}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法实现\n",
    "\n",
    "**导入相关库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**硬件与版本信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "ipywidgets 7.5.0\n",
      "matplotlib 3.1.0\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "\n",
      "compiler   : MSC v.1915 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p ipywidgets,matplotlib,numpy,pandas,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost 分类树**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeStump(object):\n",
    "    '''决策树桩\n",
    "    \n",
    "    label:\n",
    "        样本是正类（+1）还是负类（-1）,默认为正类\n",
    "    feture_index:\n",
    "        分类特征索引\n",
    "    threshold:\n",
    "        划分阈值，低于threshold 归负类，反之为正类\n",
    "    alpha:\n",
    "        分类准确率\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.label = 1\n",
    "        self.feture_index = None\n",
    "        self.threshold = None\n",
    "        self.alpha = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost(object):\n",
    "    '''自适应提升分类树\n",
    "    \n",
    "        使用高度为 2 的二叉分类树作为基分类器的 adaboost 算法实现\n",
    "        \n",
    "    clf_num:\n",
    "        基分类器数量\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, clf_num = 5):\n",
    "        \n",
    "        self.clf_num = clf_num\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        n_samples, n_features = np.shape(X_train)\n",
    "        \n",
    "        # 初始时样本权重均匀分布\n",
    "        weight = np.full(n_samples, (1 / n_samples))\n",
    "        \n",
    "        \n",
    "        # 训练各基分类器\n",
    "        self.clfs = []\n",
    "        \n",
    "        for i in range(self.clf_num):\n",
    "            \n",
    "            clf = DecisionTreeStump()\n",
    "            \n",
    "            min_error = float('inf')\n",
    "            \n",
    "            for feature_i in range(n_features):\n",
    "                \n",
    "                feature_values = np.expand_dims(X_train[:,feature_i], axis=1)\n",
    "                \n",
    "                unique_values = np.unique(feature_values)\n",
    "                \n",
    "                for threshold in unique_values:\n",
    "                    label = 1\n",
    "                    \n",
    "                    pred = np.ones(np.shape(y_train))\n",
    "                    pred[X_train[:,feature_i] < threshold] = -1\n",
    "    \n",
    "                    err = sum(weight[y_train != pred])\n",
    "              \n",
    "                    \n",
    "                    # 保证 alpha 和 err 的反比关系，错误率过半则反转类别\n",
    "                    if err > 0.5:\n",
    "                        err = 1 - err\n",
    "                        label = -1\n",
    "                       \n",
    "                    # 保留误差最小的特征\n",
    "                    if err < min_error:\n",
    "                        min_error = err\n",
    "                        clf.label = label\n",
    "                        clf.threshold = threshold\n",
    "                        clf.feature_index = feature_i\n",
    "            \n",
    "            # 更新分类器权重\n",
    "            clf.alpha = 0.5 * math.log((1-min_error) / (min_error + 1e-10))\n",
    "            \n",
    "            # 更新样本权重分布\n",
    "            pred = np.ones(np.shape(y_train))\n",
    "            neg_index = (clf.label * X_train[:,clf.feature_index] < clf.label * clf.threshold)\n",
    "            pred[neg_index] = -1\n",
    "            weight *= np.exp(-clf.alpha * y_train * pred)\n",
    "            weight /= sum(weight)\n",
    "            \n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        n_samples = np.shape(X_test)[0]\n",
    "        y_pred = np.zeros((n_samples, 1))\n",
    "        \n",
    "        for clf in self.clfs:\n",
    "            \n",
    "            pred = np.ones(np.shape(y_pred))\n",
    "            \n",
    "            neg_index = (clf.label * X_test[:,clf.feature_index] < clf.label * clf.threshold)\n",
    "            \n",
    "            pred[neg_index] = -1\n",
    "            \n",
    "            y_pred += clf.alpha * pred\n",
    "            \n",
    "        y_pred = np.sign(y_pred).flatten()\n",
    "        \n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试\n",
    "\n",
    "**导入数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_data():\n",
    "    data = load_digits()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    \n",
    "    digit_one = 1\n",
    "    digit_two = 8\n",
    "    \n",
    "    idx = np.append(np.where(y == digit_one)[0],np.where(y == digit_two)[0])\n",
    "    y = data.target[idx]\n",
    "    \n",
    "    y[y == digit_one] = -1\n",
    "    y[y == digit_two] = 1\n",
    "    X = data.data[idx]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adaboost = Adaboost()\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预测与可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.906542\n"
     ]
    }
   ],
   "source": [
    "y_pred = adaboost.predict(X_test)\n",
    "accuracy = np.sum(y_pred == y_test, axis=0) / len(y_test)\n",
    "print(\"Accuracy: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, dim):\n",
    "    '''PCA降维转换'''\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    covariance_matrix = (1 / (n_samples - 1)) * (X - X.mean(axis=0)).T.dot(X - X.mean(axis=0))\n",
    "    covariance_matrix = np.array(covariance_matrix, dtype=float)\n",
    "    \n",
    "    # 计算特征值和特征向量\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # \n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[idx][:dim]\n",
    "    eigenvectors = np.atleast_1d(eigenvectors[:,idx])[:,:dim]\n",
    "    \n",
    "    X_transformed = X.dot(eigenvectors)\n",
    "    \n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "X_transformed = transform(X_test, dim=2)\n",
    "x1 = X_transformed[:,0]\n",
    "x2 = X_transformed[:,1]\n",
    "class_distr = []\n",
    "\n",
    "y = np.array(y_pred).astype(int)\n",
    "\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(np.unique(y)))]\n",
    "\n",
    "for i, l in enumerate(np.unique(y)):\n",
    "    _x1 = x1[y==l]\n",
    "    _x2 = x2[y==l]\n",
    "    _y = y[y==l]\n",
    "    class_distr.append(plt.scatter(_x1, _x2, color = colors[i]))\n",
    "\n",
    "    \n",
    "perc = 100*accuracy\n",
    "plt.suptitle(\"Adaboost\")\n",
    "plt.title(\"Accuracy: %.1f%%\" % perc, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn 里的 Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.5,\n",
       "                   n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "cls = AdaBoostClassifier(n_estimators = 10, learning_rate = 0.5)\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 实现了两种 Adaboost 分类算法，SAMME 和 SAMME.R。两者的主要区别是弱学习器权重的度量，SAMME 用样本集分类效果作为弱学习器权重，而SAMME.R 使用分类预测概率值来作为弱学习器权重。后者是连续值所以迭代一般比 SAMME 快，因此 AdaBoostClassifier 的默认算法 algorithm 的值也是SAMME.R。注意，使用 SAMME.R 时弱分类学习器参数 base_estimator 必须限制使用支持概率预测的分类器。SAMME 算法则没有这个限制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439252336448598"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
